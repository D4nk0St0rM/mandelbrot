{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fuzzymatching_companies_house_BigQuery.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnFj5WU5BVBo"
      },
      "source": [
        "# **Finding similar company name and auto matching them**\n",
        "\n",
        "This program will use NLP and ML technique to match similar company names. \n",
        "\n",
        "Matching form common words like \"LTD\" and \"COMPANY\" will be discounted autometically in the algorithm.\n",
        "\n",
        "THIS CODE CURRENTLY USES THE COMPANY HOUSE ALL COMPANY DATABASE I HAVE IN BIG QUERY HERE:\n",
        "\n",
        "https://console.cloud.google.com/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vocBMIf8lhN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "496efff3-d4bd-4270-daf0-0c6dbff5e524"
      },
      "source": [
        "#FUZZYWUZZY MATCHING\n",
        "#INSTALL ALL THE LIBRARIES AND TOOLS NEEDED\n",
        "\n",
        "from oauth2client.service_account import ServiceAccountCredentials\n",
        "import httplib2\n",
        "from apiclient import discovery\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import gspread_dataframe as gd\n",
        "import gspread\n",
        "from gspread_dataframe import get_as_dataframe, set_with_dataframe\n",
        "\n",
        "########## YOU CAN # OUT THE FOLLOWING !pip INSTALLS AFTER THE FIRST RUN - BUT NEED REINSTALLING IF YOU RESET THE RUNTIME ENVIORNMENT\n",
        "!pip install fuzzywuzzy[speedup]\n",
        "!pip install python-Levenshtein\n",
        "!pip install fuzzywuzzy\n",
        "\n",
        "\n",
        "#SET ENVIRON VARIABLES\n",
        "\n",
        "project_id = 'fuzzy-228510'\n",
        "KEY_FILE_NAME ='/tmp/bqfuzzy.json'\n",
        "SCOPES = ['https://spreadsheets.google.com/feeds','https://www.googleapis.com/auth/drive','https://www.googleapis.com/auth/bigquery']\n",
        "\n",
        "\n",
        "#GO GET PERMISSIONS TO ACCESS API SERVICES\n",
        "#SAVED SERVICE ACCOUNT JSON CREDENTIALS ARE IN CLOUD BUCKET\n",
        "\n",
        "!gsutil cp gs://credsfuzzy/bqfuzzy.json /tmp/bqfuzzy.json\n",
        "# Print the result to make sure the transfer worked.\n",
        "#!cat /tmp/bqfuzzy.json\n",
        "credentials = ServiceAccountCredentials.from_json_keyfile_name(filename=KEY_FILE_NAME, scopes=SCOPES)\n",
        "print(\"Acquiring credentials...\")\n",
        "print(\"Authorizing...\")\n",
        "http = credentials.authorize(httplib2.Http())\n",
        "print(\"Acquiring service...\")\n",
        "service = discovery.build(serviceName=\"drive\", version=\"v3\", http=http) #, credentials=credentials) - Using both HTTP and credentials caused 'mutually exclusive error'\n",
        "print(\"Service acquired!\")\n",
        "print(\"Acquiring service...\")\n",
        "service2 = discovery.build(serviceName=\"bigquery\", version=\"v2\", http=http) #, credentials=credentials) - Using both HTTP and credentials caused 'mutually exclusive error'\n",
        "print(\"Service acquired!\")\n",
        "credentials2 = ServiceAccountCredentials.from_json_keyfile_name(filename=KEY_FILE_NAME, scopes=SCOPES)\n",
        "gc = gspread.authorize(credentials2)\n",
        "\n",
        "\n",
        "  \n",
        "#QUERY BIG QUERY DATA CONTAINING DATASET [COMPANIES HOUSE ALL DATA]\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns', 1000)\n",
        "#THIS IS THE SQL QUERY - SHOWING ONLY A's AT THE MOMENT AND LIMITING 12000 RESULTS\n",
        "\n",
        "query = \"SELECT * FROM cohse.cseprep WHERE CompanyName LIKE 'A%' LIMIT 12000\" # LIMIT 2000\"\n",
        "df = pd.io.gbq.read_gbq(query, project_id=project_id, private_key='/tmp/bqfuzzy.json', verbose=False, dialect='standard')\n",
        "\n",
        "#OK - LETS SEE WHAT WE HAVE FROM THIS!!\n",
        "df.head()\n",
        "df.columns\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fuzzywuzzy[speedup] in /usr/local/lib/python3.6/dist-packages (0.17.0)\n",
            "Requirement already satisfied: python-levenshtein>=0.12; extra == \"speedup\" in /usr/local/lib/python3.6/dist-packages (from fuzzywuzzy[speedup]) (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-levenshtein>=0.12; extra == \"speedup\"->fuzzywuzzy[speedup]) (40.6.3)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from python-Levenshtein) (40.6.3)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.6/dist-packages (0.17.0)\n",
            "Copying gs://credsfuzzy/bqfuzzy.json...\n",
            "/ [1 files][  2.3 KiB/  2.3 KiB]                                                \n",
            "Operation completed over 1 objects/2.3 KiB.                                      \n",
            "Acquiring credentials...\n",
            "Authorizing...\n",
            "Acquiring service...\n",
            "Service acquired!\n",
            "Acquiring service...\n",
            "Service acquired!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['CompanyName', '_CompanyNumber', 'RegAddress_CareOf',\n",
              "       'RegAddress_POBox', 'RegAddress_AddressLine1',\n",
              "       '_RegAddress_AddressLine2', 'RegAddress_PostTown', 'RegAddress_County',\n",
              "       'RegAddress_Country', 'RegAddress_PostCode', 'CompanyCategory',\n",
              "       'CompanyStatus', 'CountryOfOrigin', 'DissolutionDate',\n",
              "       'IncorporationDate', 'Accounts_AccountRefDay',\n",
              "       'Accounts_AccountRefMonth', 'Accounts_NextDueDate',\n",
              "       'Accounts_LastMadeUpDate', 'Accounts_AccountCategory',\n",
              "       'Returns_NextDueDate', 'Returns_LastMadeUpDate',\n",
              "       'Mortgages_NumMortCharges', 'Mortgages_NumMortOutstanding',\n",
              "       'Mortgages_NumMortPartSatisfied', 'Mortgages_NumMortSatisfied',\n",
              "       'SICCode_SicText_1', 'SICCode_SicText_2', 'SICCode_SicText_3',\n",
              "       'SICCode_SicText_4', 'LimitedPartnerships_NumGenPartners',\n",
              "       'LimitedPartnerships_NumLimPartners', 'URI', 'PreviousName_1_CONDATE',\n",
              "       '_PreviousName_1_CompanyName', '_PreviousName_2_CONDATE',\n",
              "       '_PreviousName_2_CompanyName', 'PreviousName_3_CONDATE',\n",
              "       '_PreviousName_3_CompanyName', 'PreviousName_4_CONDATE',\n",
              "       '_PreviousName_4_CompanyName', 'PreviousName_5_CONDATE',\n",
              "       '_PreviousName_5_CompanyName', 'PreviousName_6_CONDATE',\n",
              "       '_PreviousName_6_CompanyName', 'PreviousName_7_CONDATE',\n",
              "       '_PreviousName_7_CompanyName', 'PreviousName_8_CONDATE',\n",
              "       '_PreviousName_8_CompanyName', 'PreviousName_9_CONDATE',\n",
              "       '_PreviousName_9_CompanyName', 'PreviousName_10_CONDATE',\n",
              "       '_PreviousName_10_CompanyName', 'ConfStmtNextDueDate',\n",
              "       '_ConfStmtLastMadeUpDate'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSK0nYBGCwAD"
      },
      "source": [
        "# **Frequency of words**\n",
        "\n",
        "Since we have lots of companies, we will only use companies in LONDON as an example.\n",
        "\n",
        "Find the 30 most common words in all company names as we will be expecting them to be repeating a lot even in companies that is not the same, we cannot match company names using them. \n",
        "The way we do it is we will deduct the matching score of a pair if any keywords is present in the names.\n",
        "\n",
        "It might be worth playing with the variable matching here of 30 to see if it effects the matching algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb-Mmmgb91B9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c8bc3e28-889a-4a07-d7b3-f1f366c4452c"
      },
      "source": [
        "df['RegAddress_PostTown'].value_counts().head(30)\n",
        "from collections import Counter\n",
        "all_names = df['CompanyName'][df['RegAddress_PostTown']=='LONDON'].unique()\n",
        "names_freq = Counter()\n",
        "for name in all_names:\n",
        "    names_freq.update(str(name).split(\" \"))\n",
        "key_words = [word for (word,_) in names_freq.most_common(30)]\n",
        "print(key_words)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['LTD', 'LIMITED', 'SERVICES', '&', 'A', 'UK', 'GROUP', 'AND', 'CONSULTING', 'LP', 'SOLUTIONS', 'MANAGEMENT', 'INTERNATIONAL', 'INVESTMENTS', 'ALL', 'LTD.', 'LLP', 'LONDON', 'HOLDINGS', 'CAPITAL', 'TRADING', 'PROPERTY', 'PARTNERS', 'CONSULTANCY', 'ALPHA', 'GLOBAL', 'CONSTRUCTION', 'DESIGN', 'PARTNERSHIP', 'INVESTMENT']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpQNWK2B_0rM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d0d0fa65-411f-4838-f1b6-b2564a76ede9"
      },
      "source": [
        "len(all_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Anc4NXDQvi"
      },
      "source": [
        "# **Matching by Grouping**\n",
        "\n",
        "Group the names by their 1st character. As the list is too long, it will take forever to match them all at once (F'LOADS x F'ING LOADS pairs to consider). The work around is to match them by groups, assuming if the names are not matched at the 1st character, it is unlikely that they are the same name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUGqxoKHALcn"
      },
      "source": [
        "#Match by Grouping\n",
        "all_main_name = pd.DataFrame(columns=['sort_gp','names','alias','score'])\n",
        "all_names.sort()\n",
        "all_main_name['names'] = all_names\n",
        "all_main_name['sort_gp'] = all_main_name['names'].apply(lambda x: x[0])\n",
        "\n",
        "print(\"Grouping Completed\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjVI6PpuDmj_"
      },
      "source": [
        "# **Fuzzy Matching**\n",
        "\n",
        "Here for each group, we use fuzzywuzzy.token_sort_ratio to matching the names. Different form the basic fuzzywuzzy.ratio which use Levenshtein Distance to calculate the differences, it allow the token (words) in a name to swap order and still give a 'perfect' match. (ref: https://github.com/seatgeek/fuzzywuzzy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVfiAle1AcUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "outputId": "10fcc39e-44bb-452c-f869-0211e7a2690f"
      },
      "source": [
        "from fuzzywuzzy import fuzz\n",
        "\n",
        "all_sort_gp = all_main_name['sort_gp'].unique()\n",
        "\n",
        "def no_key_word(name):\n",
        "    \"\"\"check if the name contain the keywords in travel company\"\"\"\n",
        "    output = True\n",
        "    for key in key_words:\n",
        "        if key in name:\n",
        "            output = False\n",
        "    return output\n",
        "\n",
        "for sortgp in all_sort_gp:\n",
        "    this_gp = all_main_name.groupby(['sort_gp']).get_group(sortgp)\n",
        "    gp_start = this_gp.index.min()\n",
        "    gp_end = this_gp.index.max()\n",
        "    for i in range(gp_start,gp_end+1):\n",
        "    \n",
        "        # if self has not got alias, asign to be alias of itself\n",
        "        if pd.isna(all_main_name['alias'].iloc[i]):\n",
        "            all_main_name['alias'].iloc[i] = all_main_name['names'].iloc[i]\n",
        "            all_main_name['score'].iloc[i] = 100\n",
        "        \n",
        "        # if the following has not got alias and fuzzy match, asign to be alias of this one\n",
        "        for j in range(i+1,gp_end+1):\n",
        "            if pd.isna(all_main_name['alias'].iloc[j]):\n",
        "                fuzz_socre = fuzz.token_sort_ratio(all_main_name['names'].iloc[i],all_main_name['names'].iloc[j])\n",
        "                if not no_key_word(all_main_name['names'].iloc[j]):\n",
        "                    fuzz_socre -= 10\n",
        "                if (fuzz_socre > 85):\n",
        "                    all_main_name['alias'].iloc[j] = all_main_name['alias'].iloc[i]\n",
        "                    all_main_name['score'].iloc[j] = fuzz_socre\n",
        "                    \n",
        "        if i % (len(all_names)//10) == 0:\n",
        "            print(\"progress: %.2f\" % (100*i/len(all_names)) + \"%\")\n",
        "                \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "progress: 0.00%\n",
            "progress: 9.98%\n",
            "progress: 19.97%\n",
            "progress: 29.95%\n",
            "progress: 39.94%\n",
            "progress: 49.92%\n",
            "progress: 59.91%\n",
            "progress: 69.89%\n",
            "progress: 79.88%\n",
            "progress: 89.86%\n",
            "progress: 99.85%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADMIny8JAp3K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "7d29b5d8-303a-480c-eada-f93c0128058d"
      },
      "source": [
        "all_main_name[(all_main_name['names']!=all_main_name['alias']) & (all_main_name['alias'].notna())]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sort_gp</th>\n",
              "      <th>names</th>\n",
              "      <th>alias</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>A</td>\n",
              "      <td>ABERDEEN EUROPEAN INFRASTRUCTURE PARTNERS III LP</td>\n",
              "      <td>ABERDEEN EUROPEAN INFRASTRUCTURE PARTNERS II LP</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>A</td>\n",
              "      <td>ABERDEEN EUROPEAN INFRASTRUCTURE PARTNERS LP</td>\n",
              "      <td>ABERDEEN EUROPEAN INFRASTRUCTURE PARTNERS II LP</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>A</td>\n",
              "      <td>ACTIS AFRICA REAL ESTATE 3 C LP</td>\n",
              "      <td>ACTIS AFRICA REAL ESTATE 2 C LP</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>572</th>\n",
              "      <td>A</td>\n",
              "      <td>ADVENT PRIVATE EQUITY FUND II 'D'</td>\n",
              "      <td>ADVENT PRIVATE EQUITY FUND II 'C'</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>573</th>\n",
              "      <td>A</td>\n",
              "      <td>ADVENT PRIVATE EQUITY FUND III 'D'</td>\n",
              "      <td>ADVENT PRIVATE EQUITY FUND II 'C'</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>626</th>\n",
              "      <td>A</td>\n",
              "      <td>AF SOLUTIONS LTD</td>\n",
              "      <td>AAF SOLUTIONS LTD</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1442</th>\n",
              "      <td>A</td>\n",
              "      <td>AMO INTERNATIONAL LIMITED</td>\n",
              "      <td>AMH INTERNATIONAL LIMITED</td>\n",
              "      <td>86</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521</th>\n",
              "      <td>A</td>\n",
              "      <td>ANCALA UTILITIES II LP</td>\n",
              "      <td>ANCALA UTILITIES I LP</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1721</th>\n",
              "      <td>A</td>\n",
              "      <td>AP VENTURES CO-INVESTMENT II GP LLP</td>\n",
              "      <td>AP VENTURES CO-INVESTMENT I GP LLP</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1866</th>\n",
              "      <td>A</td>\n",
              "      <td>ARCC INTERNATIONAL LTD</td>\n",
              "      <td>ARC INTERNATIONAL LTD</td>\n",
              "      <td>88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2329</th>\n",
              "      <td>A</td>\n",
              "      <td>ATMALLI LIMITED</td>\n",
              "      <td>ATMALI LIMITED</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sort_gp                                             names  \\\n",
              "253        A  ABERDEEN EUROPEAN INFRASTRUCTURE PARTNERS III LP   \n",
              "254        A      ABERDEEN EUROPEAN INFRASTRUCTURE PARTNERS LP   \n",
              "421        A                   ACTIS AFRICA REAL ESTATE 3 C LP   \n",
              "572        A                 ADVENT PRIVATE EQUITY FUND II 'D'   \n",
              "573        A                ADVENT PRIVATE EQUITY FUND III 'D'   \n",
              "626        A                                  AF SOLUTIONS LTD   \n",
              "1442       A                         AMO INTERNATIONAL LIMITED   \n",
              "1521       A                            ANCALA UTILITIES II LP   \n",
              "1721       A               AP VENTURES CO-INVESTMENT II GP LLP   \n",
              "1866       A                            ARCC INTERNATIONAL LTD   \n",
              "2329       A                                   ATMALLI LIMITED   \n",
              "\n",
              "                                                alias  score  \n",
              "253   ABERDEEN EUROPEAN INFRASTRUCTURE PARTNERS II LP     89  \n",
              "254   ABERDEEN EUROPEAN INFRASTRUCTURE PARTNERS II LP     87  \n",
              "421                   ACTIS AFRICA REAL ESTATE 2 C LP     87  \n",
              "572                 ADVENT PRIVATE EQUITY FUND II 'C'     87  \n",
              "573                 ADVENT PRIVATE EQUITY FUND II 'C'     88  \n",
              "626                                 AAF SOLUTIONS LTD     87  \n",
              "1442                        AMH INTERNATIONAL LIMITED     86  \n",
              "1521                            ANCALA UTILITIES I LP     88  \n",
              "1721               AP VENTURES CO-INVESTMENT I GP LLP     89  \n",
              "1866                            ARC INTERNATIONAL LTD     88  \n",
              "2329                                   ATMALI LIMITED     87  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Bv79NiHBOs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "ac359ed1-3292-4f52-a08a-faf9f3b816cb"
      },
      "source": [
        "#LETS SEE WHAT THIS MEANS IN DATA SIZES\n",
        "len(all_main_name['alias'].unique())\n",
        "all_main_name.head()\n",
        "all_main_name.info()\n",
        "all_main_name[(all_main_name['names']!=all_main_name['alias']) & (all_main_name['alias'].notna())].shape[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2594 entries, 0 to 2593\n",
            "Data columns (total 4 columns):\n",
            "sort_gp    2594 non-null object\n",
            "names      2594 non-null object\n",
            "alias      2594 non-null object\n",
            "score      2594 non-null int64\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 81.1+ KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSqUg3bXG3h0"
      },
      "source": [
        "**Groups Normally Found:**\n",
        "\n",
        "they are usually differ in spelling by 1 character: missing an 'L' or 'I' or 'S'\n",
        "highly similar names: 'No.3' instead of 'No.2' or 'EB' instread of 'EH'\n",
        "fairly similar names: 'CATS AND HAMMERS PRODUCTIONS LIMITED' and TATS AND AMMERS PRODUCTIONS LIMITED'\n",
        "For type 1 and 2 matches it could be the same company, the diffeernce in names could be an intentional alteration or simply a typo. But it is not likely the same company for type 3 matched, it seems more like a coincidence.\n",
        "\n",
        "To further confirm, manual work need to be done."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP_0E9lpHszW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c809c308-2152-4c12-bff7-1ac1092ce469"
      },
      "source": [
        "#NOW PUSHING INTO A SPREADSHEET\n",
        "\n",
        "#THIS IS JUST THE ID FROM THE URL OF THE GOOGLE SHEET\n",
        "worksht = gc.open_by_key('1T_WNf1AMB11fzTag23DWGGxoNIMwCyT_Xw8076vCYCo')\n",
        "\n",
        "#DEFINE A CONVERSION FOR SPREADSHEET ROW | COL REF FROM DATA TO PUSH RESULTS\n",
        "\n",
        "def numberToLetters(q):\n",
        "    q = q - 1\n",
        "    result = ''\n",
        "    while q >= 0:\n",
        "        remain = q % 26\n",
        "        result = chr(remain+65) + result;\n",
        "        q = q//26 - 1\n",
        "    return result\n",
        "\n",
        "#SET DATAFRAME TO USE AS DATA\n",
        "df2 = all_main_name[(all_main_name['names']!=all_main_name['alias']) & (all_main_name['alias'].notna())]\n",
        "df2.head()\n",
        "dataframe2 = df2\n",
        "df3=all_main_name\n",
        "df3.head()\n",
        "dataframe3 = df3\n",
        "\n",
        "\n",
        "#taking dataframe count rows and columns \n",
        "pd.set_option('display.max_columns', 1000)\n",
        "num_lines, num_columns = df2.shape\n",
        "num_lines2, num_columns2 = df3.shape\n",
        "\n",
        "\n",
        "#add worksheet with timestamp as name and populate\n",
        "ws = worksht.add_worksheet(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), (num_lines+1), (num_columns))\n",
        "cell_list = ws.range('A2:'+numberToLetters(num_columns)+str(num_lines+1))\n",
        "set_with_dataframe(ws, dataframe2, row=1, col=1, include_index=False, include_column_header=True, resize=False, allow_formulas=True)\n",
        "df2.head()\n",
        "\n",
        "ws2 = worksht.add_worksheet(datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), (num_lines+1), (num_columns))\n",
        "cell_list = ws2.range('A2:'+numberToLetters(num_columns2)+str(num_lines2+1))\n",
        "set_with_dataframe(ws2, dataframe3, row=1, col=1, include_index=False, include_column_header=True, resize=False, allow_formulas=True)\n",
        "df3.head()\n",
        "\n",
        "\n",
        "#end routine\n",
        "print(\"Requested operations complete - Go to spreadsheet here: https://docs.google.com/spreadsheets/d/1T_WNf1AMB11fzTag23DWGGxoNIMwCyT_Xw8076vCYCo/edit#gid=1076096544\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requested operations complete - Go to spreadsheet here: https://docs.google.com/spreadsheets/d/1T_WNf1AMB11fzTag23DWGGxoNIMwCyT_Xw8076vCYCo/edit#gid=1076096544\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
